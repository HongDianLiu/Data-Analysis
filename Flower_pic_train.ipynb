{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import torch\n",
    "from collections import defaultdict\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.transforms import functional as TF\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from PIL import Image, ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "paths = [\n",
    "    r\"C:\\Users\\User\\Downloads\\Hackathon Blossom\\flower_data\\flower_data\\train\",\n",
    "    r\"C:\\Users\\User\\Downloads\\National Flowers\\flowerdataset\\train\",\n",
    "    r\"C:\\Users\\User\\Downloads\\üå∏  Flowers\\flowers\",\n",
    "    r\"C:\\Users\\User\\Downloads\\Flowers Recognition\\flowers\",\n",
    "    r\"C:\\Users\\User\\Downloads\\Flowers Datasets (dandelion & daisy)\\train\",\n",
    "    r\"C:\\Users\\User\\Downloads\\Flowers Dataset\\train\",\n",
    "    r\"C:\\Users\\User\\Downloads\\Indian_subcontinent_flowers\\labeled_flowers\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all images into a single directory structure\n",
    "all_images = defaultdict(list)\n",
    "\n",
    "for path in paths:\n",
    "    for folder in os.listdir(path):\n",
    "        folder_path = os.path.join(path, folder)\n",
    "        if os.path.isdir(folder_path):\n",
    "            for file in os.listdir(folder_path):\n",
    "                if file.endswith(('jpg', 'jpeg', 'png')):\n",
    "                    img_path = os.path.join(folder_path, file)\n",
    "                    try:\n",
    "                        # Attempt to open the image file to check if it's valid\n",
    "                        with Image.open(img_path) as img:\n",
    "                            img.verify()  # Verify that it is, in fact, an image\n",
    "                        all_images[folder.lower()].append(img_path)\n",
    "                    except (IOError, SyntaxError, OSError) as e:\n",
    "                        print(f\"Bad file: {img_path}, deleting...\")\n",
    "                        try:\n",
    "                            os.remove(img_path)\n",
    "                        except Exception as delete_error:\n",
    "                            print(f\"Error deleting file {img_path}: {delete_error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AugmentedDataset(datasets.ImageFolder):\n",
    "    def __init__(self, root, transform=None):\n",
    "        super(AugmentedDataset, self).__init__(root, transform)\n",
    "        self.max_count = max(len([img for img in os.listdir(os.path.join(root, cls)) if img.endswith(('jpg', 'jpeg', 'png'))]) for cls in self.classes)\n",
    "        self.image_classes = defaultdict(list)\n",
    "        for idx, (path, _) in enumerate(self.samples):\n",
    "            label = self.classes[self.targets[idx]]\n",
    "            self.image_classes[label].append(path)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        label = self.classes[index % len(self.classes)]\n",
    "        images = self.image_classes[label]\n",
    "        img_path = images[index % len(images)]\n",
    "        \n",
    "        # Load the image\n",
    "        with open(img_path, 'rb') as f:\n",
    "            img = Image.open(f)\n",
    "            img = img.convert('RGB')\n",
    "        \n",
    "        # Apply data augmentation if necessary\n",
    "        if len(images) < self.max_count:\n",
    "            img = self.augment_image(img)\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        return img, self.class_to_idx[label]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.max_count * len(self.classes)\n",
    "    \n",
    "    def augment_image(self, img):\n",
    "        # Define your augmentation here, but do not convert to tensor\n",
    "        img = img.resize((128, 128), Image.BILINEAR)\n",
    "        return img\n",
    "\n",
    "# Define transforms\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(32),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(20),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(144),\n",
    "        transforms.CenterCrop(128),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#‰øÆÊîπ‰ª•‰∏ãÊ™îÊ°àË∑ØÂæë"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the augmented dataset\n",
    "combined_dataset_path = r\"C:\\Users\\User\\Downloads\\combined_flower_dataset\"  #‰øÆÊîπÈÄôË£°\n",
    "dataset = AugmentedDataset(combined_dataset_path, transform=data_transforms['train'])\n",
    "\n",
    "# Split dataset into train, validation, and test sets\n",
    "train_size = int(0.7 * len(dataset))\n",
    "val_size = int(0.15 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# Apply the correct transform to validation and test datasets\n",
    "val_dataset.dataset.transform = data_transforms['val']\n",
    "test_dataset.dataset.transform = data_transforms['val']\n",
    "\n",
    "# Create data loaders with more workers\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "\n",
    "\n",
    "# Define the ResNet Block\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.downsample = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = self.downsample(x)\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "# Define the ResNet model\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=102):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc1 = nn.Linear(512, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, out_channels, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_channels, out_channels, stride))\n",
    "            self.in_channels = out_channels\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "def ResNet50(num_classes):\n",
    "    return ResNet(ResBlock, [3, 4, 6, 3], num_classes)\n",
    "\n",
    "model = ResNet50(num_classes=102)\n",
    "\n",
    "# Load the pretrained ResNet50 model and replace the final layer\n",
    "pretrained_model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "model.conv1 = pretrained_model.conv1\n",
    "model.bn1 = pretrained_model.bn1\n",
    "model.relu = pretrained_model.relu\n",
    "model.maxpool = pretrained_model.maxpool\n",
    "model.layer1 = pretrained_model.layer1\n",
    "model.layer2 = pretrained_model.layer2\n",
    "model.layer3 = pretrained_model.layer3\n",
    "model.layer4 = pretrained_model.layer4\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "        elif val_loss > self.best_loss - self.min_delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "\n",
    "early_stopping = EarlyStopping(patience=5, min_delta=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 25\n",
    "train_losses, val_losses = [], []\n",
    "train_accuracies, val_accuracies = [], []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss, running_corrects = 0.0, 0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)  # Á°Æ‰øùÊï∞ÊçÆË¢´ËøÅÁßªÂà∞GPU\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    epoch_acc = running_corrects.double() / len(train_loader.dataset)\n",
    "    train_losses.append(epoch_loss)\n",
    "    train_accuracies.append(epoch_acc.cpu().numpy())\n",
    "\n",
    "    model.eval()\n",
    "    val_loss, val_corrects = 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)  # Á°Æ‰øùÈ™åËØÅÊï∞ÊçÆ‰πüË¢´ËøÅÁßªÂà∞GPU\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "            val_corrects += torch.sum(preds == labels.data)\n",
    "    \n",
    "    epoch_val_loss = val_loss / len(val_loader.dataset)\n",
    "    epoch_val_acc = val_corrects.double() / len(val_loader.dataset)\n",
    "    val_losses.append(epoch_val_loss)\n",
    "    val_accuracies.append(epoch_val_acc.cpu().numpy())\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{EPOCHS}.. '\n",
    "          f'Train loss: {epoch_loss:.4f}.. '\n",
    "          f'Train accuracy: {epoch_acc:.4f}.. '\n",
    "          f'Val loss: {epoch_val_loss:.4f}.. '\n",
    "          f'Val accuracy: {epoch_val_acc:.4f}')\n",
    "\n",
    "    scheduler.step()\n",
    "    \n",
    "    early_stopping(epoch_val_loss)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping\")\n",
    "        break\n",
    "\n",
    "print('Training complete.')\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), 'resnet50_flower_model.pth')\n",
    "print('Model saved to resnet50_flower_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Loss and accuracy visualization\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Val Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss over Epochs')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_accuracies, label='Train Accuracy')\n",
    "plt.plot(val_accuracies, label='Val Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy over Epochs')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "model.eval()\n",
    "test_loss, test_corrects = 0.0, 0\n",
    "all_preds, all_labels = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        test_loss += loss.item() * inputs.size(0)\n",
    "        test_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "test_loss = test_loss / len(test_loader.dataset)\n",
    "test_accuracy = test_corrects.double() / len(test_loader.dataset)\n",
    "\n",
    "print(f'Test loss: {test_loss:.4f}.. '\n",
    "      f'Test accuracy: {test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap='Blues', xticklabels=dataset.classes, yticklabels=dataset.classes)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(all_labels, all_preds, target_names=dataset.classes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snowman",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
